{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PPOAgent import PPOAgent\n",
    "from SubEnvironment import SubEnvironment\n",
    "import time\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SubEnvironment(max_steps=512, period=128, lookback=64,\n",
    "                     frequency=(1,10), freq_var=(0,1.),\n",
    "                     amplitude=1., amp_var=(0., 0.5),\n",
    "                     noise=0.1, phase=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-08 22:03:17,411 Run Created: ./runs/agent-34/\n",
      "2019-01-08 22:03:17,436 Agen logs created.\n",
      "2019-01-08 22:03:17,440 Running Pretraining Step.\n",
      "2019-01-08 22:03:17,443 Building Models.\n",
      "2019-01-08 22:03:17,720 Beginning Training Loop.\n",
      "2019-01-08 22:03:18,423 Episode 0 done! Reward: -46.74787176926317\n",
      "2019-01-08 22:03:20,915 Episode 1 done! Reward: -26.086009661134995\n",
      "2019-01-08 22:03:21,153 Training Complete!\n"
     ]
    }
   ],
   "source": [
    "agent = PPOAgent(env, verbose=1)\n",
    "agent.run(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-08 22:06:40,654 Run Created: ./runs/agent-37/\n",
      "2019-01-08 22:06:40,657 Agen logs created.\n",
      "2019-01-08 22:06:40,658 Running Pretraining Step.\n",
      "2019-01-08 22:06:40,660 Building Models.\n",
      "2019-01-08 22:06:40,931 Beginning Training Loop.\n",
      "2019-01-08 22:06:41,073 Episode 0 done! Reward: 15.0\n",
      "2019-01-08 22:06:41,098 Episode 1 done! Reward: 17.0\n",
      "2019-01-08 22:06:41,137 Episode 2 done! Reward: 27.0\n",
      "2019-01-08 22:06:41,168 Episode 3 done! Reward: 21.0\n",
      "2019-01-08 22:06:41,201 Episode 4 done! Reward: 24.0\n",
      "2019-01-08 22:06:41,326 Episode 5 done! Reward: 88.0\n",
      "2019-01-08 22:06:41,350 Episode 6 done! Reward: 16.0\n",
      "2019-01-08 22:06:41,382 Episode 7 done! Reward: 22.0\n",
      "2019-01-08 22:06:41,411 Episode 8 done! Reward: 18.0\n",
      "2019-01-08 22:06:41,450 Episode 9 done! Reward: 30.0\n",
      "2019-01-08 22:06:43,383 Episode 10 done! Reward: 23.0\n",
      "2019-01-08 22:06:43,426 Episode 11 done! Reward: 26.0\n",
      "2019-01-08 22:06:43,457 Episode 12 done! Reward: 18.0\n",
      "2019-01-08 22:06:43,521 Episode 13 done! Reward: 45.0\n",
      "2019-01-08 22:06:43,572 Episode 14 done! Reward: 38.0\n",
      "2019-01-08 22:06:43,614 Episode 15 done! Reward: 31.0\n",
      "2019-01-08 22:06:43,691 Episode 16 done! Reward: 58.0\n",
      "2019-01-08 22:06:43,721 Episode 17 done! Reward: 21.0\n",
      "2019-01-08 22:06:43,945 Episode 18 done! Reward: 9.0\n",
      "2019-01-08 22:06:43,978 Episode 19 done! Reward: 20.0\n",
      "2019-01-08 22:06:44,025 Episode 20 done! Reward: 32.0\n",
      "2019-01-08 22:06:44,047 Episode 21 done! Reward: 12.0\n",
      "2019-01-08 22:06:44,080 Episode 22 done! Reward: 22.0\n",
      "2019-01-08 22:06:44,118 Episode 23 done! Reward: 27.0\n",
      "2019-01-08 22:06:44,174 Episode 24 done! Reward: 39.0\n",
      "2019-01-08 22:06:44,231 Episode 25 done! Reward: 41.0\n",
      "2019-01-08 22:06:44,319 Episode 26 done! Reward: 63.0\n",
      "2019-01-08 22:06:44,647 Episode 27 done! Reward: 95.0\n",
      "2019-01-08 22:06:44,806 Episode 28 done! Reward: 121.0\n",
      "2019-01-08 22:06:44,912 Episode 29 done! Reward: 78.0\n",
      "2019-01-08 22:06:45,203 Episode 30 done! Reward: 63.0\n",
      "2019-01-08 22:06:45,330 Episode 31 done! Reward: 96.0\n",
      "2019-01-08 22:06:45,381 Episode 32 done! Reward: 37.0\n",
      "2019-01-08 22:06:45,436 Episode 33 done! Reward: 43.0\n",
      "2019-01-08 22:06:45,588 Episode 34 done! Reward: 114.0\n",
      "2019-01-08 22:06:45,919 Episode 35 done! Reward: 93.0\n",
      "2019-01-08 22:06:46,028 Episode 36 done! Reward: 82.0\n",
      "2019-01-08 22:06:46,227 Episode 37 done! Reward: 149.0\n",
      "2019-01-08 22:06:46,579 Episode 38 done! Reward: 104.0\n",
      "2019-01-08 22:06:46,677 Episode 39 done! Reward: 73.0\n",
      "2019-01-08 22:06:46,786 Episode 40 done! Reward: 80.0\n",
      "2019-01-08 22:06:47,155 Episode 41 done! Reward: 122.0\n",
      "2019-01-08 22:06:47,259 Episode 42 done! Reward: 77.0\n",
      "2019-01-08 22:06:47,358 Episode 43 done! Reward: 71.0\n",
      "2019-01-08 22:06:47,678 Episode 44 done! Reward: 86.0\n",
      "2019-01-08 22:06:47,823 Episode 45 done! Reward: 108.0\n",
      "2019-01-08 22:06:47,937 Episode 46 done! Reward: 82.0\n",
      "2019-01-08 22:06:48,247 Episode 47 done! Reward: 84.0\n",
      "2019-01-08 22:06:48,428 Episode 48 done! Reward: 135.0\n",
      "2019-01-08 22:06:48,530 Episode 49 done! Reward: 73.0\n",
      "2019-01-08 22:06:48,893 Episode 50 done! Reward: 127.0\n",
      "2019-01-08 22:06:49,048 Episode 51 done! Reward: 115.0\n",
      "2019-01-08 22:06:49,209 Episode 52 done! Reward: 121.0\n",
      "2019-01-08 22:06:49,554 Episode 53 done! Reward: 104.0\n",
      "2019-01-08 22:06:49,737 Episode 54 done! Reward: 144.0\n",
      "2019-01-08 22:06:49,883 Episode 55 done! Reward: 106.0\n",
      "2019-01-08 22:06:50,262 Episode 56 done! Reward: 126.0\n",
      "2019-01-08 22:06:50,414 Episode 57 done! Reward: 117.0\n",
      "2019-01-08 22:06:50,616 Episode 58 done! Reward: 154.0\n",
      "2019-01-08 22:06:50,926 Episode 59 done! Reward: 84.0\n",
      "2019-01-08 22:06:51,086 Episode 60 done! Reward: 118.0\n",
      "2019-01-08 22:06:51,245 Episode 61 done! Reward: 124.0\n",
      "2019-01-08 22:06:51,646 Episode 62 done! Reward: 141.0\n",
      "2019-01-08 22:06:51,792 Episode 63 done! Reward: 108.0\n",
      "2019-01-08 22:06:51,933 Episode 64 done! Reward: 104.0\n",
      "2019-01-08 22:06:52,320 Episode 65 done! Reward: 136.0\n",
      "2019-01-08 22:06:52,449 Episode 66 done! Reward: 96.0\n",
      "2019-01-08 22:06:52,589 Episode 67 done! Reward: 100.0\n",
      "2019-01-08 22:06:52,925 Episode 68 done! Reward: 110.0\n",
      "2019-01-08 22:06:53,052 Episode 69 done! Reward: 92.0\n",
      "2019-01-08 22:06:53,172 Episode 70 done! Reward: 90.0\n",
      "2019-01-08 22:06:53,495 Episode 71 done! Reward: 98.0\n",
      "2019-01-08 22:06:53,667 Episode 72 done! Reward: 126.0\n",
      "2019-01-08 22:06:53,788 Episode 73 done! Reward: 87.0\n",
      "2019-01-08 22:06:54,120 Episode 74 done! Reward: 104.0\n",
      "2019-01-08 22:06:54,269 Episode 75 done! Reward: 111.0\n",
      "2019-01-08 22:06:54,421 Episode 76 done! Reward: 112.0\n",
      "2019-01-08 22:06:54,759 Episode 77 done! Reward: 104.0\n",
      "2019-01-08 22:06:54,922 Episode 78 done! Reward: 125.0\n",
      "2019-01-08 22:06:55,078 Episode 79 done! Reward: 116.0\n",
      "2019-01-08 22:06:55,398 Episode 80 done! Reward: 84.0\n",
      "2019-01-08 22:06:55,539 Episode 81 done! Reward: 104.0\n",
      "2019-01-08 22:06:55,686 Episode 82 done! Reward: 101.0\n",
      "2019-01-08 22:06:56,022 Episode 83 done! Reward: 102.0\n",
      "2019-01-08 22:06:56,189 Episode 84 done! Reward: 124.0\n",
      "2019-01-08 22:06:56,335 Episode 85 done! Reward: 101.0\n",
      "2019-01-08 22:06:56,662 Episode 86 done! Reward: 93.0\n",
      "2019-01-08 22:06:56,811 Episode 87 done! Reward: 110.0\n",
      "2019-01-08 22:06:56,977 Episode 88 done! Reward: 124.0\n",
      "2019-01-08 22:06:57,317 Episode 89 done! Reward: 106.0\n",
      "2019-01-08 22:06:57,440 Episode 90 done! Reward: 92.0\n",
      "2019-01-08 22:06:57,553 Episode 91 done! Reward: 84.0\n",
      "2019-01-08 22:06:57,878 Episode 92 done! Reward: 90.0\n",
      "2019-01-08 22:06:58,013 Episode 93 done! Reward: 102.0\n",
      "2019-01-08 22:06:58,153 Episode 94 done! Reward: 103.0\n",
      "2019-01-08 22:06:58,479 Episode 95 done! Reward: 91.0\n",
      "2019-01-08 22:06:58,618 Episode 96 done! Reward: 100.0\n",
      "2019-01-08 22:06:58,767 Episode 97 done! Reward: 117.0\n",
      "2019-01-08 22:06:59,120 Episode 98 done! Reward: 107.0\n",
      "2019-01-08 22:06:59,347 Episode 99 done! Reward: 168.0\n",
      "2019-01-08 22:06:59,562 Training Complete!\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "agent = PPOAgent(env, verbose=1)\n",
    "agent.run(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from sidecar import Sidecar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './runs/agent-27/data/animations/meta_plot/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-02980fc297a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrun_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./runs/agent-27/data/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mframe_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"animations/meta_plot/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mframe_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mline_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlog_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'agent.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './runs/agent-27/data/animations/meta_plot/'"
     ]
    }
   ],
   "source": [
    "run_dir = \"./runs/agent-27/data/\"\n",
    "line_limit = 10\n",
    "log_path = run_dir + 'agent.txt'\n",
    "log_val = []\n",
    "kill_thread = False\n",
    "last_frame_count = 0\n",
    "empty_frame_count = 0\n",
    "\n",
    "def update_log():\n",
    "    log_val = ['<li><code style=\"font-size: 10px;\">{}</code></li>'.format(line) for \n",
    "               line in list(open(log_path))[-line_limit:]]\n",
    "    log_widget.value = '<ul style=\"list-style-type: none; padding: 0;\">' + ''.join(log_val) + '</ul>'\n",
    "    \n",
    "def on_change(x):\n",
    "    if (x['name'] == 'value'):\n",
    "        update_image(x['new'])\n",
    "        \n",
    "def kill_thread_click(x):\n",
    "    global kill_thread\n",
    "    kill_thread = True\n",
    "        \n",
    "def live_update():\n",
    "    global last_frame_count\n",
    "    global empty_frame_count\n",
    "    while True:\n",
    "        update_count_widget.value = \"Last Update: \" + time.strftime('%c')\n",
    "        update_log()\n",
    "        if last_frame_count == frame_count:\n",
    "            empty_frame_count += 1\n",
    "        else:\n",
    "            last_frame_count = frame_count\n",
    "            empty_frame_count = 0\n",
    "        if empty_frame_count > 10 or kill_thread:\n",
    "            update_count_widget.value = 'Halted: ' + time.strftime('%c')\n",
    "            break\n",
    "        time.sleep(1)\n",
    "\n",
    "play_widget = widgets.Play(\n",
    "    interval=250,\n",
    "    value=frame_count,\n",
    "    min=0,\n",
    "    max=frame_count,\n",
    "    step=1,\n",
    "    description=\"Press play\",\n",
    "    disabled=False\n",
    ")\n",
    "slider_widget = widgets.IntSlider(max=frame_count)\n",
    "image_widget = widgets.Image(format='png', height=100)\n",
    " \n",
    "slider_widget.observe(on_change)\n",
    "widgets.jslink((play_widget, 'value'), (slider_widget, 'value'))\n",
    "\n",
    "log_widget = widgets.HTML()\n",
    "\n",
    "update_count_widget = widgets.Label()\n",
    "\n",
    "kill_button_widget = widgets.Button(\n",
    "    description='Kill Thread'\n",
    ")\n",
    "kill_button_widget.on_click(kill_thread_click)\n",
    "\n",
    "thread = threading.Thread(target=live_update)\n",
    "thread.start()\n",
    "\n",
    "training_info = widgets.VBox([image_widget,\n",
    "                      widgets.HBox([kill_button_widget, play_widget, slider_widget, update_count_widget]),\n",
    "                      log_widget])\n",
    "\n",
    "sc = Sidecar(title='Training Info')\n",
    "with sc:\n",
    "    display(training_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
